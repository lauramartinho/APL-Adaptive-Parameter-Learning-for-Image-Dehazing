# -*- coding: utf-8 -*-
"""DEHAZE_REGRESSION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10TpoV3guHSwufFMcCVcxeX-EJhoGIjTT

## **Código do melhoramento de imagem**
"""

import cv2
from google.colab.patches import cv2_imshow

import cv2

from scipy import ndimage
from scipy.ndimage import gaussian_filter

from PIL import Image, ImageOps
import matplotlib.pyplot as plt

from skimage.metrics import peak_signal_noise_ratio, structural_similarity
from skimage import io, color, filters, measure

import math
import numpy as np

import os
import sys
from glob import glob
from os.path import join
from ntpath import basename


from PIL import Image

import sklearn

from sklearn.model_selection import train_test_split, KFold, GridSearchCV

import scikeras
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from keras.wrappers.scikit_learn import KerasRegressor

def enhance_segmentation(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    masking = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
    inv_masking = cv2.bitwise_not(masking)
    corrected_areas = mascaraNitidez(image, 1.0, 3.0, kernel=(5, 5), threshold=0)
    masked = cv2.bitwise_and(image, image, mask=inv_masking)
    masked += cv2.bitwise_and(corrected_areas, corrected_areas, mask=masking)
    return masked

def colorCorrection(imagem, intensidade):
  resultados = [] #vetor para receber os resultados das trasnformações
  rgb = cv2.split(imagem) #acesso a cada canal de cor
  saturacao = rgb[0].shape[0] * rgb[0].shape[1] * intensidade / 200.0 #200
  for canal in rgb:
      histograma = cv2.calcHist([canal], [0], None, [256], (0,256), accumulate=False)
      #low value
      lowvalue = np.searchsorted(np.cumsum(histograma), saturacao) #soma acumulada dos elementos valor inferior do histograma e encontra índices onde os elementos devem ser inseridos p/ ordenar
      #high value
      highvalue = 255-np.searchsorted(np.cumsum(histograma[::-1]), saturacao)#soma acumulada e sort valores superiores
      #tomar toda a informação (min/max) da curva linear para aplicar e gerar uma LUT de 256 valores a aplicar nos canais stretching
      lut = np.array([0 if i < lowvalue else (255 if i > highvalue else round(float(i-lowvalue)/float(highvalue-lowvalue)*255)) for i in np.arange(0, 256)], dtype="uint8")
      #mescla os canais de volta
      resultados.append(cv2.LUT(canal, lut))
  return cv2.merge(resultados)

# Função para ajustar o contraste e a luminosidade da imagem
def adjust_gamma(image, gamma=0.95):
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(np.uint8)
    return cv2.LUT(image, table)

def mascaraNitidez(imagem, sigma, intensidade, kernel=(5, 5), threshold=0): #sigma 1.0/ 0.5, intensidade 2.0/ 1.0
  suavizacao = cv2.GaussianBlur(imagem, kernel, sigma)
  nitidez = float(intensidade + 1) * imagem - float(intensidade) * suavizacao
  nitidez = np.maximum(nitidez, np.zeros(nitidez.shape))
  nitidez = np.minimum(nitidez, 255 * np.ones(nitidez.shape))
  nitidez = nitidez.round().astype(np.uint8)
  if threshold > 0:
      contraste_baixo = np.absolute(imagem - suavizacao) < threshold
      np.copyto(nitidez, imagem, where=contraste_baixo)
  return nitidez

def ajustar_exposicao(imagem, exposicao, contraste, brilho):
    # Ajusta a exposição
    imagem_ajustada = np.clip(imagem * exposicao, 0, 255)
    # Ajusta o contraste e brilho
    imagem_ajustada = np.clip((imagem_ajustada - 127) * contraste + 127 + brilho, 0, 255)
    return imagem_ajustada.astype(np.uint8)

def dehaze(image, cci, gamma, exposicao): #1.0, 0.8, 1.0

    imagem = enhance_segmentation(image)
    z = colorCorrection(imagem, cci)

    w = adjust_gamma(z, gamma)
    contraste = 1.2
    brilho = 0.8

    imagem_ajustada_2 = ajustar_exposicao(w, exposicao, contraste, brilho)

    return imagem_ajustada_2

# def dehaze(image, cci, gamma): #1.0, 0.8, 1.0

#     imagem = enhance_segmentation(image)
#     z = colorCorrection(imagem, cci)

#     w = adjust_gamma(z, gamma)


#     return w

image = cv2.imread('/content/33_outdoor_hazy.jpg')

imagem = enhance_segmentation(image)
z = colorCorrection(imagem, 2.0)
w = adjust_gamma(z, 0.9)
contraste = 1.2
brilho = 0.8
imagem_ajustada_2 = w


fig, axs = plt.subplots(1, 5, figsize=(30, 20))

axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
axs[0].axis('off')
axs[0].set_title('Raw Image')

axs[1].imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB))
axs[1].axis('off')
axs[1].set_title('Enhanced Segmentation')

axs[2].imshow(cv2.cvtColor(z, cv2.COLOR_BGR2RGB))
axs[2].axis('off')
axs[2].set_title('Color Corrected')

axs[3].imshow(cv2.cvtColor(w, cv2.COLOR_BGR2RGB))
axs[3].axis('off')
axs[3].set_title('Gamma Adjusted')

axs[4].imshow(cv2.cvtColor(imagem_ajustada_2, cv2.COLOR_BGR2RGB))
axs[4].axis('off')
axs[4].set_title('Exposure Adjusted - Final')

plt.show()

cv2_imshow(dehaze(image, 2.0, 0.85, 0.8))

"""###**Métricas de qualidade**"""

!pip install piq

from skimage import color, io
import numpy as np

def getNIQE(img):# Carregue a imagem usando scikit-image (substitua 'imagem.jpg' pelo caminho da sua imagem)
    # Converta a imagem para escala de cinza
    imagem_gray = color.rgb2gray(img)

    # Calcule a média e o desvio padrão do contraste local
    mean_local_contrast = np.mean(np.abs(np.gradient(imagem_gray)))
    std_local_contrast = np.std(np.abs(np.gradient(imagem_gray)))

    # Calcule o NIQE
    niqe_score = 1.0 / (1 + 6.6 * mean_local_contrast + 0.228 * std_local_contrast)

    return niqe_score

def calculate_mscn_coefficients(image):
    c = np.fft.fft2(image)
    c_shifted = np.fft.fftshift(c)
    magnitude = np.abs(c_shifted)
    log_magnitude = np.log(1.0 + magnitude)
    c_shifted_real = np.real(c_shifted)
    c_shifted_imag = np.imag(c_shifted)
    return c_shifted_real, c_shifted_imag, magnitude, log_magnitude

def calculate_mscn_features(image):
    c_shifted_real, c_shifted_imag, _, log_magnitude = calculate_mscn_coefficients(image)
    std_dev = np.std(log_magnitude)
    mean = np.mean(log_magnitude)
    return [std_dev, mean]

def brisque_features(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    ms_std_dev, ms_mean = calculate_mscn_features(gray)
    return [ms_std_dev, ms_mean]

def getBRISQUE(image):
    features = brisque_features(image)
    weights = [-0.0977446, 0.0270277, 0.00090095, 0.0793246, 0.0476165, -0.033992, -0.0535509, 0.276186, 0.189205, 0.255546,
               0.120626, 0.0471861, -0.18469, 0.154051, -0.173411, -0.413456]
    intercept = 18.9217
    score = intercept
    for i in range(len(features)):
        score += features[i] * weights[i]
    return score

# Exemplo de uso
image_path = '/content/drive/MyDrive/boa.jpg'
image = cv2.imread(image_path)
score1 = getBRISQUE(image)
score2 = getNIQE(imagem)
print('Pontuação BRISQUE da imagem:', score1)
print('Pontuação NIQE da imagem:', score2)

"""###Loop"""

def resize(src, scale_percent):
    width = int(src.shape[1] * scale_percent / 100)
    height = int(src.shape[0] * scale_percent / 100)
    dsize = (width, height)
    output = cv2.resize(src, dsize)
    return output

def escreve(arquivo, vetor):
  with open(arquivo, 'w') as writefile:
    for h in range(len(vetor)):
      writefile.write(str(vetor[h]) + '\n')

def maior_valor(lista):
  if(len(lista) > 0):

    maior_valor = [lista[0][4], lista[0][5]]
    maior_indice = 0

    for i in range(0, len(lista)):
      if((lista[i][4] > maior_valor[0]) and (lista[i][5] > maior_valor[1])):
        maior_valor[0] = lista[i][4]
        maior_valor[1] = lista[i][5]
        maior_indice = i
    return maior_valor, maior_indice
  return -1, -1

import cv2
from google.colab import drive
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

import os
import shutil
# Diretório onde as imagens estão localizadas
diretorio = "/content/drive/MyDrive/UWE/Laura_ImpactLab/Datasets/Tahi_CVPR_Results"

# Lista todos os arquivos no diretório
arquivos = os.listdir(diretorio)

# Inicializa o contador de imagens
contador_imagens = 0

# Itera sobre todos os arquivos no diretório
for arquivo in arquivos:
    # Verifica se o arquivo é uma imagem (png, jpg, jpeg, etc.)
    if arquivo.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
        contador_imagens += 1

print(f"Total de imagens na pasta: {contador_imagens}")
#1280

#############################alteradoooooooooooo


DIR = '/content/drive/MyDrive/UWE/Laura_ImpactLab/Datasets/Dataset_Tahi/' #diretório das imagens
DIR_results = '/content/drive/MyDrive/UWE/Laura_ImpactLab/Datasets/Tahi_CVPR_Results/'
# arquivo = '/content/drive/MyDrive/tahi.txt'
# melhores_resultados = [] #vetor que receberá os resultados

#percorrer pasta de arquivos
for filename in sorted(os.listdir(DIR)):
#   resultados=[] #lista que recebe a string contendo os dados (imagem, parâmetros e resultados qualidade)
  caminho_img = f'{DIR}/{filename}'

#   img = cv2.imread(caminho_img)
  imgem = cv2.imread(caminho_img)
  img = resize(imgem, 50)

  print(filename)
  restored = dehaze(img, 2.0, 0.85, 0.8)



#   #parâmetros que serão testados
#   cci = [1.0, 2.0] #intensidade de correcao de cor
#   gamma = [0.8, 0.9] #intensidade do gamma
#   exposicao =[0.8, 0.9, 1.0] #intensidade do alfa da combinação

#   for i in range(len(cci)):
#     for j in range(len(gamma)):
#       for m in range(len(exposicao)):
#         # for n in range(len(beta)):

#         #image, cci, gamma, alfa, beta, sigma=0.5, intensidade=1.0, brightness=5, contrast=10
#         restored = dehaze(img, cci[i], gamma[j], exposicao[m])

#         #metricas de qualidade
#         niq = getNIQE(restored)
#         briq = getBRISQUE(restored)

#         #psnr = peak_signal_noise_ratio(img, restored)
#         #ssim = structural_similarity(img, restored,  multichannel=True)

#         string = str(filename), str(cci[i]), str(gamma[j]), str(exposicao[m]), "{:.4f}".format(niq), "{:.4f}".format(briq)
#         resultados.append(string)

#   maior, indice = maior_valor(resultados)

#   if(maior != -1 and indice != -1):
#     melhores_resultados.append(resultados[indice])

#   print(f'maior {maior}, indice {indice}, vetor[indice] {resultados[indice]}')

#   my_str = '_'.join(resultados[indice]) .replace('0', '').replace('.', '').replace('png', "") + '.png'
#   print(my_str)

  cv2.imwrite(f'{DIR_results}{filename}', restored)
# escreve(arquivo, melhores_resultados)

DIR = '/content/drive/MyDrive/UWE/Laura_ImpactLab/Datasets/Dataset_Tahi/' #diretório das imagens
DIR_results = '/content/drive/MyDrive/UWE/Laura_ImpactLab/Datasets/Tahi_Results/'
arquivo = '/content/drive/MyDrive/tahi.txt'
melhores_resultados = [] #vetor que receberá os resultados

#percorrer pasta de arquivos
for filename in sorted(os.listdir(DIR)):
  resultados=[] #lista que recebe a string contendo os dados (imagem, parâmetros e resultados qualidade)
  caminho_img = f'{DIR}/{filename}'

#   img = cv2.imread(caminho_img)
  imgem = cv2.imread(caminho_img)
  img = resize(imgem, 50)

  print(filename)

  #parâmetros que serão testados
  cci = [1.0, 2.0] #intensidade de correcao de cor
  gamma = [0.8, 0.9] #intensidade do gamma
  exposicao =[0.8, 0.9, 1.0] #intensidade do alfa da combinação

  for i in range(len(cci)):
    for j in range(len(gamma)):
      for m in range(len(exposicao)):
        # for n in range(len(beta)):

        #image, cci, gamma, alfa, beta, sigma=0.5, intensidade=1.0, brightness=5, contrast=10
        restored = dehaze(img, cci[i], gamma[j], exposicao[m])

        #metricas de qualidade
        niq = getNIQE(restored)
        briq = getBRISQUE(restored)

        #psnr = peak_signal_noise_ratio(img, restored)
        #ssim = structural_similarity(img, restored,  multichannel=True)

        string = str(filename), str(cci[i]), str(gamma[j]), str(exposicao[m]), "{:.4f}".format(niq), "{:.4f}".format(briq)
        resultados.append(string)

  maior, indice = maior_valor(resultados)

  if(maior != -1 and indice != -1):
    melhores_resultados.append(resultados[indice])

  print(f'maior {maior}, indice {indice}, vetor[indice] {resultados[indice]}')

  my_str = '_'.join(resultados[indice]) .replace('0', '').replace('.', '').replace('png', "") + '.png'
  print(my_str)
  cv2.imwrite(f'{DIR_results}{str(my_str)}', restored)
escreve(arquivo, melhores_resultados)

"""## **Código do Modelo**

####Carregamento e tratamento de imagens e labels
"""

import os
import numpy as np
from PIL import Image

def mapear_rotulos(filename):
    partes = filename.split("_")

    # Mapear cci
    cci = 1.0 if partes[2] == '1' else 2.0

    # Mapear gamma
    gamma_str = partes[3]
    gamma = 0.8 if gamma_str == '8' else 0.9

    # Mapear exposicao
    expo_str = partes[4]
    exposicao = 0.8 if expo_str == '8' else 0.9 if expo_str == '9' else 1.0

    return [cci, gamma, exposicao]

caminho_pasta = "/content/drive/MyDrive/HAZE_RESULTS"

imagens = []
rotulos = []

for arquivo in os.listdir(caminho_pasta):
    if arquivo.endswith(".png"):
        try:
            rotulo = mapear_rotulos(arquivo)
        except ValueError:
            continue
        imagem = Image.open(os.path.join(caminho_pasta, arquivo))
        imagem = imagem.resize((64, 64))

        imagem_array = np.array(imagem)

        imagens.append(imagem_array)
        rotulos.append(rotulo)

imagens = np.array(imagens)
rotulos = np.array(rotulos)

print(rotulos)

"""#### Divisao Treino teste"""

X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(
    imagens, rotulos, test_size=0.2, random_state=42
)
#normalizar pixels:
X_treinamento = X_treinamento / 255.0
X_teste = X_teste / 255.0

"""#### K fold Cross Validation"""

num_folds = 5

acuracias = []

kf = KFold(n_splits=num_folds, shuffle=True)

"""#### Modelo da CNN"""

def criar_modelo():
    modelo = Sequential([
        layers.Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(64, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(3)
    ])

    modelo.compile(optimizer='adam', loss='mse', metrics=['accuracy'])
    return modelo


modelo = criar_modelo()
print(modelo.summary())

modelo = KerasRegressor(build_fn=criar_modelo)

parametros = {
    'batch_size': [16,64],
    'epochs': [10,15]
}

grid_search = GridSearchCV(estimator=modelo, param_grid=parametros, scoring='neg_mean_absolute_error', cv=kf)
grid_search.fit(imagens, rotulos)

resultados = grid_search.cv_results_
melhores_parametros = grid_search.best_params_
melhor_acuracia = -grid_search.best_score_

print("\nMelhores parâmetros:")
print(melhores_parametros)

print("Acurácia média:")
print(melhor_acuracia)
print("")

print("Todos os Resultados:\n")
for indice, parametro_combinacao in enumerate(resultados['params']):
    acuracia = -resultados['mean_test_score'][indice]
    print(f"Combinação de parâmetros: {parametro_combinacao}")
    print(f"Acurácia: {acuracia}")
    print("")

"""#### Versão testada com o melhor resultado"""

modelo = Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(3)
])


# Compila o modelo
modelo.compile(optimizer='adam', loss='mse', metrics=['accuracy'])

# Treina o modelo
historicofinal = modelo.fit(X_treinamento, y_treinamento, epochs=15, batch_size=16, verbose=1)

# Avalia o modelo no conjunto de teste
perda, acuracia = modelo.evaluate(X_teste, y_teste, verbose=0)
print(f"Acurácia no conjunto de teste: {acuracia} ({acuracia * 100}%)")

# Plotar gráfico de acurácia
plt.plot(historicofinal.history['accuracy'])
plt.title('Acurácia do Modelo')
plt.xlabel('Época')
plt.ylabel('Acurácia')
plt.show()

# Plotar gráfico de perda
plt.plot(historicofinal.history['loss'])
plt.title('Perda do Modelo')
plt.xlabel('Época')
plt.ylabel('Perda')
plt.show()

"""#### Teste para predizer valores dos parametros para uma imagem qualquer"""

modelo = Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(3)
])


# Compila o modelo
modelo.compile(optimizer='adam', loss='mse', metrics=['accuracy'])

# Treina o modelo
historicofinal = modelo.fit(X_treinamento, y_treinamento, epochs=20, batch_size=64, verbose=1)

# Avalia o modelo no conjunto de teste
perda, acuracia = modelo.evaluate(X_teste, y_teste, verbose=0)
print(f"Acurácia no conjunto de teste: {acuracia} ({acuracia * 100}%)")

# Plotar gráfico de acurácia
plt.plot(historicofinal.history['accuracy'])
plt.title('Acurácia do Modelo')
plt.xlabel('Época')
plt.ylabel('Acurácia')
plt.show()

# Plotar gráfico de perda
plt.plot(historicofinal.history['loss'])
plt.title('Perda do Modelo')
plt.xlabel('Época')
plt.ylabel('Perda')
plt.show()

def clip_predictions(predictions, lower_limit, upper_limit):
    return np.clip(predictions, lower_limit, upper_limit)

# Faz previsões em novas imagens

DIR_IMG = '/content/drive/MyDrive/DEFFOGGING/VIDEO_1_RESULTS/nanchang_18_8_8_1_17421_1977.png'
imagem_nova = Image.open(DIR_IMG)
imagem_nova = imagem_nova.resize((64, 64))  # Redimensiona a imagem para o mesmo tamanho das imagens de treinamento
imagem_nova_array = np.array(imagem_nova) / 255.0  # Normaliza os valores dos pixels
imagem_nova_array = np.expand_dims(imagem_nova_array, axis=0)  # Adiciona uma dimensão extra para a amostra única

predicao = modelo.predict(imagem_nova_array)

predicao_clip = clip_predictions(predicao, 0.8, 2.0)

cci_pred = round(predicao_clip[0][0], 1 )
gamma_pred = round(predicao_clip[0][1],1 )
exp_pred = round(predicao_clip[0][2],1 )

img = cv2.imread(DIR_IMG)
restored = dehaze(img, cci_pred, gamma_pred, exp_pred)
# restored2 = dehaze(img, 1.0, 1.0, 1.0)

print("CCI:", cci_pred, "Gamma:", gamma_pred, "Exposicao:", exp_pred)

cv2_imshow(img)
cv2_imshow(restored)
# cv2_imshow(restored2)

"""#### Previsao de um exemplo do conjunto de teste"""

import cv2
from google.colab.patches import cv2_imshow
indice_teste = 14 # Índice do exemplo de teste a ser selecionado
imagem_teste = X_teste[indice_teste]
rotulo_real = y_teste[indice_teste]

# Faz a previsão do exemplo de teste
imagem_teste_array = np.expand_dims(imagem_teste, axis=0)
predicao_teste_1 = modelo.predict(imagem_teste_array)[0]

predicao_teste = clip_predictions(predicao_teste_1, 0.8, 2.0)


imagem_teste_bgr = cv2.cvtColor((imagem_teste * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)
# Exibe a imagem de teste

cci_real = round(rotulo_real[0] , 1)
gamma_real = round(rotulo_real[1] , 1)
exp_real = round(rotulo_real[2] , 1)
print(rotulo_real)

cci_predito = round(predicao_teste[0] , 1)
gamma_predito = round(predicao_teste[1] , 1)
exp_predito = round(predicao_teste[2] , 1)
print(predicao_teste)

print("Valores Reais:")
print("CCI: {:.1f}".format(cci_real), "Gamma: {:.1f}".format(gamma_real), "Exposicao: {:.1f}".format(exp_real))

cv2_imshow(imagem_teste_bgr)

print("Valores Preditos:")
print("CCI: {:.1f}".format(cci_predito), "Gamma: {:.1f}".format(gamma_predito), "Exposicao: {:.1f}".format(exp_predito))

restored = dehaze(imagem_teste_bgr, cci_predito, gamma_predito, exp_predito)
cv2_imshow(restored)

"""#### Avaliar todos os testes"""

#FUNCAO AUXILIAR
def escreve(arquivo, vetor):
  with open(arquivo, 'w') as writefile:
    for h in range(len(vetor)):
      writefile.write(str(vetor[h]) + '\n')

arquivo = '/content/drive/MyDrive/haze_2.txt'
resultados = []
for indice_teste in range(len(X_teste)):
    # Obter a imagem de teste e o rótulo real
    imagem_teste = X_teste[indice_teste]
    rotulo_real = y_teste[indice_teste]

    # Fazer a previsão do exemplo de teste
    imagem_teste_array = np.expand_dims(imagem_teste, axis=0)
    predicao_teste_2 = modelo.predict(imagem_teste_array)[0]

    predicao_teste = clip_predictions(predicao_teste_2, 0.8, 2.0)

    imagem_teste_bgr = cv2.cvtColor((imagem_teste * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)

    cci_predito = round(predicao_teste[0] , 1)
    gamma_predito = round(predicao_teste[1] , 1)
    exp_predito = round(predicao_teste[2] , 1)

    # Aplicar os valores preditos à imagem de teste e obter a imagem aprimorada
    restored = dehaze(imagem_teste_bgr, cci_predito, gamma_predito, exp_predito)

    # Calcular as métricas de qualidade
    Niq = getNIQE(restored)
    Brisq = getBRISQUE(restored)

    # Armazenar os resultados
    string = f"{indice_teste}, {cci_predito:.1f}, {gamma_predito:.1f}, {exp_predito:.1f}, {Niq:.4f}, {Brisq:.4f}"
    resultados.append(string)
escreve(arquivo, resultados)

import pandas as pd

# Ler o arquivo de texto
with open('/content/drive/MyDrive/haze_2.txt', 'r') as file:
    linhas = file.readlines()

# Criar uma lista vazia para armazenar os dados
dados = []

# Percorrer as linhas e dividir os valores pelo separador ','
for linha in linhas:
    valores = linha.strip().split(',')
    dados.append(valores)

# Criar um DataFrame usando os dados
df = pd.DataFrame(dados, columns=['Imagem', 'CCI', 'Gamma', 'Exposicao', 'Niqe', 'Brisque'])

# Salvar o DataFrame em um arquivo Excel
df.to_excel('tabela2.xlsx', index=False)

# Calcular a média dos valores da coluna 'Uciqe'
media_Niqe = df['Niqe'].astype(float).mean()

# Calcular a média dos valores da coluna 'UIQM'
media_Brisque = df['Brisque'].astype(float).mean()

print(f"Média de Niqe: {media_Niqe}")
print(f"Média de Brisqe: {media_Brisque}")
